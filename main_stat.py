import json

from numpy import size
from funcs_stat import *
import os

# Channel lists, to be used for metrics calculation

channel_list = ['express', 'hum', 'ptv', 'samaa']
channel_list_2 = ['express']

# Array for various size limits to be imposed

size_arr = np.arange(20, 85, 5)

# Array for various pose limits to be imposed

pose_arr = []
for i in range(6):
    lol = 70 - (i*5)
    lol2 = lol - 20
    lol3 = [lol, lol, lol2]
    pose_arr.append(lol3)


# Various arrays for metric calculations and graph plotting

small_count = np.zeros(len(size_arr))
size_acc = np.zeros(len(size_arr))
total_size = np.zeros(len(size_arr))

invalid_count = np.zeros(len(pose_arr))
pose_acc = np.zeros(len(pose_arr))
total_pose = np.zeros(len(pose_arr))


if __name__ == '__main__':

    # Some initial variables

    hp_iter_counter = 0
    total_considered = 0
    defaulted_frames = ""

    legend_str = ""

    # Starting with the outermost loop for iterating over sizes

    for base_size in size_arr:

        # Now iterating over various poses

        for base_pose in pose_arr:
            legend_str = legend_str + str(hp_iter_counter) + ": base_size = [" + str(base_size) + ", " + str(base_size) + "]" + ",   base_pose = " + str(base_pose) + "\n\n"

            # Innermost loop is for iterating over the channel names, as listed in the channel list.
            # However, currently the loop is only optimized for single channel (maybe make this the outermost loop?)

            for channel_name in channel_list_2:
                preds = os.path.join(channel_name, "infered_results")
                annotated = os.path.join(channel_name, "infered_results_final")
                print("\n**********************\n")
                print("Channel: ", channel_name)
                print("Size Limit: ", base_size)
                print("Pose Limit: ", base_pose)
                det_TP = 0
                det_FP = 0
                det_FN = 0
                rec_TP = 0
                rec_FP = 0
                rec_FN = 0

                small_faces = 0
                invalid_poses = 0

                # We now start iterations over individual filenames in the specificed channel

                for filename in os.listdir(preds):

                    # Loading prediction json from filename

                    with open(os.path.join(preds, filename)) as f:
                        pred_data = json.load(f)

                    # Loading corresponding annotated json file, as generated by the ground truth script

                    with open(os.path.join(annotated, filename)) as g:
                        anot_data = json.load(g)
                   
                    # Similarly, initializing some variables

                    missed = 0
                    det_local_tp = 0
                    rec_local_tp = 0

                    local_rec_FP = 0
                    local_rec_FN = 0
                    rejecc = 0

                    lmao = 0
                    
                    # For this file, we first iterate over all labels in prediction as outer loop

                    for i in range(len(pred_data['Bbox'])):
                        validated = 0
                        pred_box = pred_data['Bbox'][i]
                        anot_ind = 0
                        grt_IOU = 0

                        # The inner loop then iterates over the annotation labels

                        for j in range(len(anot_data['Bbox'])):
                            anot_box = anot_data['Bbox'][j]
                            
                            # Within this loop, we first calculate the Intersection-Over-Union metric for the current predicted and
                            # annotation label. If the IOU comes out to be over 0.35, and higher than the previous highest IOU, the labels
                            # are assigned a correspondence. By looping over all the labels, we will ultimately get the correct corresponding
                            # box.

                            IOU = bb_intersection_over_union(pred_box, anot_box)
                            
                            if IOU > 0.35:
                                if IOU > grt_IOU:
                                    validated = 1
                                    anot_ind = j
                                    grt_IOU = IOU

                        # If the label has been validated i.e the prediction label found a match in annotation for at least 0.35 IOU,
                        # whether multiple or single (In case of multiple IOUs over 0.35, highest is chosen as per previous loop), then
                        # the following detection metric calculation runs.

                        if validated == 1:
                            det_TP += 1
                            det_local_tp += 1
                            
                            pred_label = pred_data['Label'][i]
                            anot_comparator = anot_data['Label'][anot_ind]

                            rec_val = 0

                            given_size = pred_data['size'][i]
                            given_pose = pred_data['Pose'][i]

                            # These are 2 functions, made to determine whether this particular predicted label's size and
                            # pose are valid. If they are, they return 1

                            size_val = calcSize(base_size, given_size)
                            pose_val = calcPose(base_pose, given_pose)
                            
                            # Adding the count of small faces and invalid poses within the recognition metrics

                            if size_val == 0:
                                small_faces += 1
                            if pose_val == 0:
                                invalid_poses += 1
                            
                            # This part of the code makes sure that only faces within the given constraints are considered within the 
                            # recognition metrics.

                            if pred_label != 'small face' and pred_label != 'Invalid Pose' and size_val == 1 and pose_val == 1:
                                if pred_label == anot_comparator:
                                    rec_local_tp += 1
                                    rec_TP += 1
                                elif pred_label == 'Unknown':
                                    local_rec_FN += 1
                                else:
                                    local_rec_FP += 1

                    rec_FN = rec_FN + local_rec_FN
                    rec_FP = rec_FP + local_rec_FP
                    
                    local_det_FP = len(pred_data['Bbox']) - det_local_tp
                    local_det_FN = len(anot_data['Bbox']) - det_local_tp
                    
                    # Keeping track of what filenames within each channel are defaulters, for each individual constraint.

                    if local_rec_FP > 0 or local_rec_FN > 0:
                        defaulter_dict = {"Size Limit" : base_size,"Pose Limit" :  base_pose, "Channel" : channel_name, "Filename" :  filename}
                        defaulter_dict = str(defaulter_dict) + "\n\n"
                        defaulted_frames =  defaulted_frames + defaulter_dict

                    # Adding local counts to global counts

                    det_FP = det_FP + len(pred_data['Bbox']) - det_local_tp
                    det_FN = det_FN + len(anot_data['Bbox']) - det_local_tp
                
                # Printing of Detection summary - True Positives, False Positives, and False Negatives

                print("\nDetection")
                print("True Positives: ", det_TP)
                print("False Positives: ", det_FP)
                print("False Negatives: ", det_FN)

                # Calculation and Printing of Detection Metrics - Precision, Recall, and F1 Score

                det_precision = det_TP / (det_TP + det_FP)
                det_recall = det_TP / (det_TP + det_FN)
                det_f1s = 2 * ((det_precision * det_recall) / (det_precision + det_recall))

                print("Precision: ", det_precision)
                print("Recall: ", det_recall)
                print("F1 Score: ", det_f1s)
                

                # Printing of Recognition summary - True Positives, False Positives, and False Negatives

                print("\nRecognition")
                print("True Positives: ", rec_TP)
                print("False Positives: ", rec_FP)
                print("False Negatives: ", rec_FN)

                # Calculation and Printing of Recognition Metrics - Precision, Recall, and F1 Score

                if (rec_TP + rec_FP) > 0 and (rec_TP + rec_FN) > 0:
                    rec_precision = rec_TP / (rec_TP + rec_FP)
                    rec_recall = rec_TP / (rec_TP + rec_FN)
                    rec_f1s = 2 * ((rec_precision * rec_recall) / (rec_precision + rec_recall))
                else:
                    rec_precision = 0
                    rec_recall = 0
                    rec_f1s = 0

                print("Precision: ", rec_precision)
                print("Recall: ", rec_recall)
                print("F1 Score: ", rec_f1s)
                
                # This part of the code does some housekeeping, and ultimately writes to the arrays for
                # metrics calculations and graph plotting

                rec_acc = rec_TP / (rec_TP + rec_FP + rec_FN)

                total_considered = total_considered + (rec_TP + rec_FP + rec_FN)

                small_face_perc = small_faces / (rec_TP + rec_FP + rec_FN + small_faces)
                small_face_perc = small_face_perc * 100

                invalid_pose_perc = invalid_poses / (rec_TP + rec_FP + rec_FN + invalid_poses)
                invalid_pose_perc = invalid_pose_perc * 100

                pitch = base_pose[0]
                index = (pitch - 45) / 5
                index = len(pose_arr) - index - 1
                index = int(index)

                invalid_count[index] = invalid_count[index] + invalid_poses
                pose_acc[index] = pose_acc[index] + rec_TP
                total_pose[index] = total_pose[index] + rec_TP + rec_FP + rec_FN + invalid_poses

                pitch = base_size
                index = (pitch - 20) / 5
                index = index 
                index = int(index)

                small_count[index] = small_count[index] + small_faces
                size_acc[index] = size_acc[index] + rec_TP
                total_size[index] = total_size[index] + rec_TP + rec_FP + rec_FN + small_faces

                # We now create dictionary objects for both detection and recognition, containing each's metadata
                # These dicts are then written to a txt file with the same name as the channel

                det_dict = {"True Positives" : det_TP, "False Positives" : det_FP, "False Negatives" : det_FN, "Precision" : det_precision, "Recall" : det_recall, "F1 Score" : det_f1s}
                rec_dict = {"True Positives" : rec_TP, "False Positives" : rec_FP, "False Negatives" : rec_FN, "Precision" : rec_precision, "Recall" : rec_recall, "F1 Score" : rec_f1s}
                
                dict = {"Channel" : channel_name, "Key" : hp_iter_counter, "Size" : int(base_size), "Pose" : base_pose, "Small Faces" : small_faces, "Invalid Poses" : invalid_poses, "Recognition Metrics" : rec_dict, "Detection Metrics" : det_dict}
                #print(dict)

                saver_string = channel_name + ".txt"
                if os.path.exists(saver_string):
                    g = open(saver_string)
                    welp = g.read()
                    welp = str(welp) + "\n\n" + str(dict)
                    with open(saver_string, 'w') as f:
                        f.write(welp)
                else:
                    with open(saver_string, 'w') as f:
                        f.write(str(dict))
            
            hp_iter_counter += 1

    # The defaulted frames are now written to a txt file with the title "problem_frames.txt"

    with open("problem_frames.txt", 'w') as f:
        f.write(str(defaulted_frames))


    # A legend is created, detailing the size and pose limits on each iteration, along with its numbering

    with open("legend.txt", 'w') as f:
        f.write(legend_str)
    
    # Printing a  summary of the final result

    print("Total Considered: ", total_considered)
    print("Size Array: ", size_arr)
    print("Small Count: ", small_count / total_size)
    print("Size Accuracy: ", size_acc / total_size)
    print("Total Size: ", total_size, "\n\n")


    print("Pose Array: ", pose_arr)
    pose_arr_mod = [i[0] for i in pose_arr]
    print("Modified Pose Array: ", pose_arr_mod)
    print("Invalid Count: ", invalid_count / total_pose)
    print("Pose Accuracy: ", pose_acc / total_pose)

    # Creation of plots for size and pose limits, and their corresponding accuracies and eliminations

    plot_stat(size_arr, ((small_count / total_size) * 100), channel_list_2[0], size=1, acc=0)
    plot_stat(size_arr, ((size_acc / (total_size - small_count)) * 100), channel_list_2[0], size=1, acc=1)
    plot_stat(pose_arr_mod, ((invalid_count / total_pose) * 100), channel_list_2[0], size=0, acc=0)
    plot_stat(pose_arr_mod, ((pose_acc / (total_pose - invalid_count)) * 100), channel_list_2[0], size=0, acc=1)